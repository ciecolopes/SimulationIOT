# ğŸš€ Pipeline de Stream de Dados em Tempo Real do aplicativo Pede Pronto

## Bem-vindo!

Bem-vindo ao projeto de Pipeline de Stream de Dados de Ponta a Ponta do aplicativo Pede Pronto, onde o cliente realiza o pedido no restaurante, o restaurante atualiza o status do pedido e o cliente no final faz a avaliaÃ§Ã£o do pedido!

## Sobre o Projeto

O projeto serve como um pipeline abrangente de transmissÃ£o de dados em tempo real

## ğŸ› ï¸ Componentes Principais

- ğŸ“Š **Dispositivos IoT**: Criado um simulador de envio de sensores e dispositivos implatados no aplicativo do cliente e dos restaurantes.
- ğŸ› ï¸ **Apache Kafka**: Um sistema de mensagens escalÃ¡vel e tolerante a falhas para ingestÃ£o e processamento de fluxos de dados.
- ğŸ› ï¸ **Apache Spark**: Um poderoso motor para processamento e anÃ¡lise de dados em tempo real, garantindo geraÃ§Ã£o rÃ¡pida de insights.
- ğŸ› ï¸ **Docker**: Tecnologia de containerizaÃ§Ã£o para empacotar e implantar nossos componentes de pipeline com facilidade.
- ğŸ› ï¸ **AWS Cloud**: Infraestrutura em nuvem para armazenamento e processamento de dados escalÃ¡veis e confiÃ¡veis.
- ğŸ› ï¸ **AWS Glue**: ServiÃ§o de integraÃ§Ã£o de dados sem servidor para automatizar operaÃ§Ãµes ETL e tarefas de transformaÃ§Ã£o de dados.
- ğŸ› ï¸ **AWS Athena**: ServiÃ§o de consulta interativa para analisar dados armazenados no Amazon S3 usando consultas SQL padrÃ£o.
- ğŸ› ï¸ **AWS Redshift**: SoluÃ§Ã£o de data warehouse totalmente gerenciada, otimizada para anÃ¡lises de alto desempenho e consultas complexas.
- ğŸ› ï¸ **Power BI, Looker Studio, QuickSight**: Ferramenta de inteligÃªncia de negÃ³cios para visualizar e explorar dados com dashboards interativos e insights impulsionados por ML.

## ğŸŒŸ ExploraÃ§Ã£o Detalhada

1. **IngestÃ£o de Dados**: IngestÃ£o em tempo real de dados de dispositivos IoT (simulador em python) no Apache Kafka para processamento.
2. **Processamento de Dados**: UtilizaÃ§Ã£o do Apache Spark para processamento e anÃ¡lise em tempo real dos fluxos de dados.
3. **Armazenamento de Dados**: Armazenamento seguro dos dados processados no AWS S3 e Redshift para anÃ¡lise e visualizaÃ§Ã£o posterior.
4. **VisualizaÃ§Ã£o de Dados**: VisualizaÃ§Ã£o de insights e tendÃªncias usando o Power Bi, Looker Studio ou atÃ© mesmo o AWS QuickSight

## ğŸ“Š AnÃ¡lises com Power BI

O Power BI Ã© uma suÃ­te de ferramentas de anÃ¡lise de negÃ³cios desenvolvida pela Microsoft, projetada para transformar dados brutos em insights visuais e interativos. Ele permite que os usuÃ¡rios conectem-se a uma ampla variedade de fontes de dados, criem relatÃ³rios detalhados e dashboards interativos, e compartilhem esses insights com outras partes interessadas dentro da organizaÃ§Ã£o.

## ğŸ“Š AnÃ¡lises com Looker Studio

O Looker Studio, anteriormente conhecido como Google Data Studio, Ã© uma plataforma de inteligÃªncia de negÃ³cios e visualizaÃ§Ã£o de dados desenvolvida pelo Google. Ele permite que os usuÃ¡rios criem relatÃ³rios e dashboards interativos a partir de diversas fontes de dados, facilitando a anÃ¡lise e a comunicaÃ§Ã£o de insights de maneira visual e intuitiva.

## ğŸ“Š AnÃ¡lises com QuickSight

Conjunto de ferramentas de inteligÃªncia de negÃ³cios de prÃ³xima geraÃ§Ã£o que oferece dashboards interativos, anÃ¡lises preditivas e geraÃ§Ã£o de insights impulsionados por ML, permitindo que as partes interessadas visualizem e explorem dados com clareza e agilidade sem precedentes.

## ğŸš€ Arquitetura/Fluxos de Trabalho

![313504181-321a5329-edc2-4715-b8d9-77e03a70341e](https://github.com/ciecolopes/SimulationIOT/blob/main/arquitetura.jpg?raw=true)

## ğŸ™ï¸ Componentes do Sistema

- **docker-compose.yml**: Configura o ambiente hospedando o broker Kafka, Zookeeper e nÃ³s Spark.
- **main.py**: Simulador com a geraÃ§Ã£o de dados, criaÃ§Ã£o de tÃ³picos Kafka (producer.py) e processamento inicial de dados.
- **producer.py**: Function para criaÃ§Ã£o de tÃ³picos Kafka.
- **spark-pedepronto.py**: Consome dados dos tÃ³picos Kafka e os transmite para os buckets designados do Amazon S3.
